{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T21:06:58.085150Z","iopub.status.busy":"2023-10-11T21:06:58.084790Z","iopub.status.idle":"2023-10-11T21:06:58.092575Z","shell.execute_reply":"2023-10-11T21:06:58.091427Z","shell.execute_reply.started":"2023-10-11T21:06:58.085121Z"},"trusted":true},"outputs":[],"source":["import os\n","import pickle\n","import random\n","from tqdm import tqdm\n","\n","import cv2\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, Subset, random_split\n","from torchvision.transforms import Compose, RandomHorizontalFlip, ColorJitter, RandomAffine, RandomErasing, ToTensor, Resize\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","\n","import numpy as np\n","import pandas as pd\n","import pydicom"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["BATCH_SIZE = 128"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T21:06:58.110326Z","iopub.status.busy":"2023-10-11T21:06:58.109215Z","iopub.status.idle":"2023-10-11T21:06:58.123748Z","shell.execute_reply":"2023-10-11T21:06:58.122746Z","shell.execute_reply.started":"2023-10-11T21:06:58.110292Z"},"trusted":true},"outputs":[],"source":["BASEDIR = '../rsna-2023-abdominal-trauma-detection'\n","\n","TRAIN_IMG_PATH = os.path.join(BASEDIR, 'train_images')\n","TRAIN_META_PATH = os.path.join(BASEDIR, 'train_series_meta.csv')\n","TEST_IMG_PATH = os.path.join(BASEDIR, 'test_images')\n","TEST_META_PATH = os.path.join(BASEDIR, 'test_series_meta.csv')\n","\n","TRAIN_LABEL_PATH = os.path.join(BASEDIR, 'train.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T21:06:58.127541Z","iopub.status.busy":"2023-10-11T21:06:58.126269Z","iopub.status.idle":"2023-10-11T21:06:58.138968Z","shell.execute_reply":"2023-10-11T21:06:58.137900Z","shell.execute_reply.started":"2023-10-11T21:06:58.127511Z"},"trusted":true},"outputs":[],"source":["def fetch_img_paths_png():\n","    img_paths = []\n","    \n","    ppp = '../rsna-2023-png/train_images/'\n","    # ppp = '/kaggle/input/rsna-abdominal-trauma-detection-png-pt1'\n","    \n","    all_pngs = sorted(os.listdir(ppp))\n","    all_pngs = [os.path.join(ppp, d) for d in all_pngs]\n","    \n","    cur_ps = []\n","    png = all_pngs[0]\n","    prev = png[:png.rfind('_')]\n","    \n","    for png in tqdm(all_pngs):\n","        patient_series = png[:png.rfind('_')]\n","        if prev == patient_series:\n","            cur_ps.append(png)\n","        else:\n","            img_paths.append(cur_ps)\n","            cur_ps = [png]\n","        prev = patient_series\n","\n","    if cur_ps:  # to make sure the last group is added too\n","        img_paths.append(cur_ps)\n","    \n","    return img_paths\n","\n","def preprocess_png(png_path):\n","    img = cv2.imread(png_path)\n","    img = cv2.resize(img, (512, 512))\n","    greyscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)/255\n","    return greyscale"]},{"cell_type":"markdown","metadata":{},"source":["## Dataloader"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T21:06:58.141361Z","iopub.status.busy":"2023-10-11T21:06:58.140652Z","iopub.status.idle":"2023-10-11T21:06:58.159646Z","shell.execute_reply":"2023-10-11T21:06:58.158557Z","shell.execute_reply.started":"2023-10-11T21:06:58.141328Z"},"trusted":true},"outputs":[],"source":["def interpolate_channels(img_tensor):\n","    # Get the current number of channels\n","    C, H, W = img_tensor.shape\n","\n","    # Initialize the output tensor\n","    output = torch.zeros((160, H, W))\n","\n","    # Handle the edge case when C is 1\n","    if C == 1:\n","        for i in range(160):\n","            output[i] = img_tensor[0]\n","        return output\n","\n","    # Handle the edge case when C is 2\n","    if C == 2:\n","        for i in range(80):\n","            output[i] = img_tensor[0]\n","        for i in range(80, 160):\n","            output[i] = img_tensor[1]\n","        return output\n","\n","    # If channels are already 80 or more, return the original image\n","    if C >= 160:\n","        return img_tensor\n","\n","    # Set the first and last channels\n","    output[0] = img_tensor[0]\n","    output[159] = img_tensor[-1]\n","\n","    # Calculate the step for even spacing\n","    step = 158 / (C - 2)\n","\n","    # Evenly space the remaining original channels in the range 1-78\n","    for i in range(1, C - 1):\n","        output[int(1 + i * step)] = img_tensor[i]\n","\n","    # Perform linear interpolation\n","    for i in range(1, 159):\n","        if output[i].sum() == 0:\n","            left = i - 1\n","            right = i + 1\n","            while output[left].sum() == 0:\n","                left -= 1\n","            while output[right].sum() == 0:\n","                right += 1\n","\n","            alpha = (i - left) / (right - left)\n","\n","            output[i] = (1 - alpha) * output[left] + alpha * output[right]\n","\n","    return output\n","\n","\n","\n","class AbdominalData(Dataset):\n","    def __init__(self, df_path=TRAIN_LABEL_PATH, max_channel=4):\n","        super().__init__()\n","        \n","        # collect all the image instance paths\n","        self.img_paths = fetch_img_paths_png()\n","        self.max_channel = max_channel\n","                \n","        df = pd.read_csv(df_path, index_col='patient_id')\n","        self.df_dict = df.to_dict(orient='index')\n","        for key, value in self.df_dict.items():\n","            self.df_dict[key] = list(value.values())\n","            \n","        df_meta = pd.read_csv(TRAIN_META_PATH)\n","        df_meta['ps'] = df_meta['patient_id'].astype(str) + \"_\" + df_meta['series_id'].astype(str)\n","        self.df_meta_dict = df_meta.set_index('ps')['incomplete_organ'].to_dict()\n","\n","        \n","    def __len__(self):\n","        return len(self.img_paths)\n","    \n","    def __getitem__(self, idx):\n","        dicom_images = self.img_paths[idx]\n","        \n","        patient_id = int(dicom_images[0].split('/')[-1].split('_')[0])\n","        series_id = int(dicom_images[0].split('/')[-1].split('_')[1])\n","        \n","        images = []\n","        \n","        for d in dicom_images:\n","            image = preprocess_png(d)\n","            images.append(image)\n","        \n","        images = np.stack(images)\n","        image = torch.tensor(images, dtype = torch.float32).unsqueeze(dim = 1)\n","        image = self.transform(image).squeeze(dim = 1) # torch.Size([1727, 512, 512])\n","        image = interpolate_channels(image)\n","        center_idx = image.shape[0] // 2\n","        image = image[center_idx-80:center_idx+80:4]\n","                \n","        label = self.df_dict[patient_id]\n","        #incomplete_organ = self.df_meta_dict[ps]\n","\n","        # labels\n","        # bowel = np.argmax(label[0:2], keepdims = False )\n","        # extravasation = np.argmax(label[2:4], keepdims = False)\n","        # kidney = np.argmax(label[4:7], keepdims = False)\n","        # liver = np.argmax(label[7:10], keepdims = False)\n","        # spleen = np.argmax(label[10:], keepdims = False)\n","        bowel = label[0:2]\n","        extravasation = label[2:4]\n","        kidney = label[4:7]\n","        liver = label[7:10]\n","        spleen = label[10:13]\n","                \n","        return image, {\n","            'bowel': bowel,\n","            'extravasation': extravasation,\n","            'kidney': kidney,\n","            'liver': liver,\n","            'spleen': spleen,\n","            # 'incomplete_organ': incomplete_organ\n","        }"]},{"cell_type":"markdown","metadata":{},"source":["## Net"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T21:07:00.098514Z","iopub.status.busy":"2023-10-11T21:07:00.097458Z","iopub.status.idle":"2023-10-11T21:07:00.105297Z","shell.execute_reply":"2023-10-11T21:07:00.104670Z","shell.execute_reply.started":"2023-10-11T21:07:00.098463Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1500653/1500653 [00:00<00:00, 1918512.06it/s]\n"]}],"source":["data = AbdominalData()\n","train_size = int(0.8 * len(data))\n","val_size = len(data) - train_size\n","train_data, val_data = random_split(data, [train_size, val_size])\n","train_dataloader = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True)\n","val_dataloader = DataLoader(val_data, batch_size = BATCH_SIZE, shuffle = False)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T21:07:17.202384Z","iopub.status.busy":"2023-10-11T21:07:17.201506Z","iopub.status.idle":"2023-10-11T21:07:17.208898Z","shell.execute_reply":"2023-10-11T21:07:17.207966Z","shell.execute_reply.started":"2023-10-11T21:07:17.202349Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([160, 512, 512])\n","torch.Size([40, 512, 512])\n","torch.Size([40, 512, 512])\n"]}],"source":["test = torch.randn(1, 512, 512)\n","image = interpolate_channels(test)\n","print(image.shape)\n","center_idx = image.shape[0] // 2\n","image = image[center_idx-80:center_idx+80:4]\n","print(image.shape)\n","\n","img, _ = data[0]\n","print(img.shape)\n","# train_dataloader = next(iter(train_dataloader))\n","# print(train_dataloader[0].shape)\n","# y = train_dataloader[1]\n","# for k in y:\n","#     y[k] = torch.stack(y[k]).transpose(0, 1)\n","# y\n","# from IPython.display import clear_output, display\n","# import time\n","# import matplotlib.pyplot as plt\n","\n","# print(data[1620])\n","# l = data[1620][0].shape[0]\n","# for i, img in enumerate(data[1620][0]):    \n","#     plt.figure(figsize=(5, 5))\n","#     plt.imshow(img, cmap=\"gray\")\n","#     plt.title(f\"Frame {i}/{l}\")\n","#     plt.axis(False)\n","#     plt.show()\n","#     clear_output(wait=True)\n","#     time.sleep(0.01)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Created SummaryWriter, saving to: runs/2023-10-12/kaggle/unet-vit/v0\n"]}],"source":["from train_test_utils import create_writer\n","from RSNA_model import RSNA_model\n","\n","device = torch.device('cuda:5')\n","\n","unet = RSNA_model().to(device)\n","optimizer = torch.optim.Adam(unet.parameters(), lr = 1e-3)\n","writer = create_writer(\"kaggle\", \"unet-vit\", \"v0\")\n","\n","criterion_bowel = nn.BCEWithLogitsLoss().to(device)\n","criterion_extravasation = nn.BCEWithLogitsLoss().to(device)\n","criterion_kidney = nn.CrossEntropyLoss().to(device)\n","criterion_liver = nn.CrossEntropyLoss().to(device)\n","criterion_spleen = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["\n","from typing import Dict, List, Tuple\n","import pdb\n","\n","def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               optimizer: torch.optim.Optimizer, scheduler: None,\n","               device: torch.device) -> Tuple[float, float]:\n","\n","    # Put model in train mode\n","    model.train()\n","\n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0, 0\n","\n","    # Loop through data loader data batches\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Send data to target device\n","        X = X.to(device)\n","        for k in y:\n","            y[k] = torch.stack(y[k]).transpose(0, 1).to(dtype=torch.float32)\n","            y[k] = y[k].to(device)\n","\n","        # 1. Forward pass\n","        y_pred = model(X)\n","\n","        # 2. Calculate  and accumulate loss\n","        loss_b = criterion_bowel(y_pred[0], y[\"bowel\"])\n","        loss_e = criterion_extravasation(y_pred[1], y[\"extravasation\"])\n","        loss_k = criterion_kidney(y_pred[2], y[\"kidney\"].argmax(dim=1))\n","        loss_l = criterion_liver(y_pred[3], y[\"liver\"].argmax(dim=1))\n","        loss_s = criterion_spleen(y_pred[4], y[\"spleen\"].argmax(dim=1))\n","        \n","        total_loss = loss_b + loss_e + loss_k + loss_l + loss_s\n","        train_loss += total_loss.item()\n","\n","        # 3. Optimizer zero grad\n","        optimizer.zero_grad()\n","\n","        # 4. Loss backward\n","        total_loss.backward()\n","\n","        # 5. Optimizer step\n","        optimizer.step()\n","\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Calculate and accumulate accuracy metric across all batches\n","        acc_b = (torch.argmax(y_pred[0], dim=1) == torch.argmax(y[\"bowel\"], dim=1)).sum().item()\n","        acc_e = (torch.argmax(y_pred[1], dim=1) == torch.argmax(y[\"extravasation\"], dim=1)).sum().item()\n","        acc_k = (torch.argmax(y_pred[2], dim=1) == torch.argmax(y[\"kidney\"], dim=1)).sum().item()\n","        acc_l = (torch.argmax(y_pred[3], dim=1) == torch.argmax(y[\"liver\"], dim=1)).sum().item()\n","        acc_s = (torch.argmax(y_pred[4], dim=1) == torch.argmax(y[\"spleen\"], dim=1)).sum().item()\n","        \n","        train_acc += (acc_b + acc_e + acc_k + acc_l + acc_s) / 5\n","\n","    # Adjust metrics to get average loss and accuracy per batch\n","    train_loss = train_loss / len(dataloader)\n","    train_acc = train_acc / len(dataloader)\n","    return train_loss, train_acc\n","\n","\n","def test_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              device: torch.device) -> Tuple[float, float]:\n","\n","    # Put model in eval mode\n","    model.eval()\n","\n","    # Setup test loss and test accuracy values\n","    test_loss, test_acc = 0, 0\n","\n","    # Turn on inference context manager\n","    with torch.inference_mode():\n","        # Loop through DataLoader batches\n","        for batch, (X, y) in enumerate(dataloader):\n","            # Send data to target device\n","            X = X.to(device)\n","            for k in y:\n","                y[k] = torch.stack(y[k]).transpose(0, 1).to(dtype=torch.float32) # [B, 2/3]        \n","                y[k] = y[k].to(device)\n","\n","            # 1. Forward pass\n","            test_pred_logits = model(X)\n","\n","            # 2. Calculate and accumulate loss\n","            loss_b = criterion_bowel(test_pred_logits[0], y[\"bowel\"])\n","            loss_e = criterion_extravasation(test_pred_logits[1], y[\"extravasation\"])\n","            loss_k = criterion_kidney(test_pred_logits[2], y[\"kidney\"].argmax(dim=1))\n","            loss_l = criterion_liver(test_pred_logits[3], y[\"liver\"].argmax(dim=1))\n","            loss_s = criterion_spleen(test_pred_logits[4], y[\"spleen\"].argmax(dim=1))\n","            \n","            total_loss = loss_b + loss_e + loss_k + loss_l + loss_s\n","            test_loss += total_loss.item()\n","\n","            # Calculate and accumulate accuracy\n","            acc_b = (torch.argmax(test_pred_logits[0], dim=1) == torch.argmax(y[\"bowel\"], dim=1)).sum().item()\n","            acc_e = (torch.argmax(test_pred_logits[1], dim=1) == torch.argmax(y[\"extravasation\"], dim=1)).sum().item()\n","            acc_k = (torch.argmax(test_pred_logits[2], dim=1) == torch.argmax(y[\"kidney\"], dim=1)).sum().item()\n","            acc_l = (torch.argmax(test_pred_logits[3], dim=1) == torch.argmax(y[\"liver\"], dim=1)).sum().item()\n","            acc_s = (torch.argmax(test_pred_logits[4], dim=1) == torch.argmax(y[\"spleen\"], dim=1)).sum().item()\n","            \n","            test_acc += (acc_b + acc_e + acc_k + acc_l + acc_s) / 5\n","\n","    # Adjust metrics to get average loss and accuracy per batch\n","    test_loss = test_loss / len(dataloader)\n","    test_acc = test_acc / len(dataloader)\n","    return test_loss, test_acc\n","\n","\n","# Add writer parameter to train()\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          test_dataloader: torch.utils.data.DataLoader,\n","          optimizer: torch.optim.Optimizer,\n","          scheduler: None,\n","          epochs: int,\n","          device: torch.device,\n","          writer: torch.utils.tensorboard.writer.SummaryWriter # new parameter to take in a writer\n","          ) -> Dict[str, List]:\n","\n","    # Create empty results dictionary\n","    results = {\"train_loss\": [],\n","               \"train_acc\": [],\n","               \"test_loss\": [],\n","               \"test_acc\": []\n","    }\n","\n","    # Loop through training and testing steps for a number of epochs\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model=model,\n","                                          dataloader=train_dataloader,\n","                                          optimizer=optimizer,\n","                                          scheduler = scheduler,\n","                                          device=device)\n","        test_loss, test_acc = test_step(model=model,\n","          dataloader=test_dataloader,\n","          device=device)\n","\n","        # Print out what's happening\n","        print(\n","          f\"Epoch: {epoch+1} | \"\n","          f\"train_loss: {train_loss:.4f} | \"\n","          f\"train_acc: {train_acc:.4f} | \"\n","          f\"test_loss: {test_loss:.4f} | \"\n","          f\"test_acc: {test_acc:.4f}\"\n","        )\n","\n","        # Update results dictionary\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","\n","\n","        ### New: Use the writer parameter to track experiments ###\n","        # See if there's a writer, if so, log to it\n","        if writer:\n","            writer.add_scalar(tag = \"Train Loss\", scalar_value = train_loss, global_step = epoch)\n","            writer.add_scalar(tag = \"Test Loss\", scalar_value = test_loss, global_step = epoch)\n","            writer.add_scalar(tag = \"Train Acc\", scalar_value = train_acc, global_step = epoch)\n","            writer.add_scalar(tag = \"Test Acc\", scalar_value = test_acc, global_step = epoch)\n","\n","            writer.add_graph(model = model,\n","                             input_to_model = torch.randn(32, 3, 224, 224).to(device))\n","\n","\n","    if writer:\n","        writer.close()\n","\n","    return results\n","\n","import matplotlib.pyplot as plt\n","# Plot loss curves of a model\n","def plot_loss_curves(results):\n","    loss = results[\"train_loss\"]\n","    test_loss = results[\"test_loss\"]\n","\n","    accuracy = results[\"train_acc\"]\n","    test_accuracy = results[\"test_acc\"]\n","\n","    epochs = range(len(results[\"train_loss\"]))\n","\n","    plt.figure(figsize=(15, 7))\n","\n","    # Plot loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, loss, label=\"train_loss\")\n","    plt.plot(epochs, test_loss, label=\"test_loss\")\n","    plt.title(\"Loss\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend()\n","\n","    # Plot accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n","    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n","    plt.title(\"Accuracy\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1 [00:00<?, ?it/s]"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["train(unet, train_dataloader, \n","    val_dataloader, \n","    optimizer,\n","    scheduler=None,\n","    epochs=1,\n","    device=device,\n","    writer=writer\n",")\n","\n","torch.save(obj=unet.state_dict(), f=\"./unet.pth\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
